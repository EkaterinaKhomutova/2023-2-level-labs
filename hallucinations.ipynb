{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNs45CUSpxIv35G5HkO8093",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EkaterinaKhomutova/2023-2-level-labs/blob/main/hallucinations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "g = open('gazeta_test.jsonl',encoding='utf-8')\n",
        "pairs= []\n",
        "mini_texts = []\n",
        "titles =[]\n",
        "texts1 = []\n",
        "for line in g:\n",
        "    data = json.loads(line)\n",
        "    pairs.append([data['text'],data['summary']])\n",
        "    mini_texts.append(data['summary'])\n",
        "    titles.append([data['summary'],data['title']])\n",
        "    texts1.append(data['text'])\n"
      ],
      "metadata": {
        "id": "Yf8RJnUMCChz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers\n",
        "from sentence_transformers import CrossEncoder\n",
        "import numpy as np\n",
        "model = CrossEncoder('vectara/hallucination_evaluation_model')"
      ],
      "metadata": {
        "id": "UwwXdkdNEjdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.predict(pairs[:50]) #проверка являются ли галлюцинациями суммаризации, сделанные человеком\n",
        "print(scores)"
      ],
      "metadata": {
        "id": "q5pCz8fCEqN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.predict(pairs[50:100])\n",
        "print(scores)"
      ],
      "metadata": {
        "id": "cPVTkdVxYf1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.predict(pairs[100:200])\n",
        "print(scores)"
      ],
      "metadata": {
        "id": "4Z9nrTkZY4wZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l = [0.60316813, 0.7303682 , 0.778796  , 0.96096957, 0.9673141 ,  #результат работы модели на 200 парах\n",
        "       0.3860174 , 0.95845467, 0.8462403 , 0.8074054 , 0.8923748 ,\n",
        "       0.30424294, 0.9781336 , 0.650528  , 0.59594584, 0.86033124,\n",
        "       0.3162132 , 0.9311179 , 0.70862836, 0.08628415, 0.6947835 ,\n",
        "       0.33818623, 0.88199365, 0.49237397, 0.665211  , 0.5613542 ,\n",
        "       0.5731333 , 0.4346374 , 0.90298367, 0.57890743, 0.96091056,\n",
        "       0.98923546, 0.94909173, 0.47569472, 0.97150224, 0.52049226,\n",
        "       0.6703585 , 0.4877524 , 0.39702567, 0.94016296, 0.8668292 ,\n",
        "       0.90818274, 0.7440704 , 0.7014002 , 0.9744572 , 0.6746498 ,\n",
        "       0.90026873, 0.7326263 , 0.70092386, 0.6088957 , 0.5006265,\n",
        "       0.8638189 , 0.8892276 , 0.03183967, 0.78920025, 0.7906439 ,\n",
        "       0.41667026, 0.02179581, 0.60558766, 0.7468622 , 0.70555425,\n",
        "       0.08213592, 0.88994026, 0.95832634, 0.29832536, 0.30345917,\n",
        "       0.72003937, 0.41597944, 0.6752646 , 0.7804789 , 0.7228683 ,\n",
        "       0.56327623, 0.59831005, 0.54116917, 0.92353165, 0.82499135,\n",
        "       0.81111324, 0.5658175 , 0.85800004, 0.76624906, 0.5995245 ,\n",
        "       0.636221  , 0.9854311 , 0.6168453 , 0.9533031 , 0.8862033 ,\n",
        "       0.6557439 , 0.7775316 , 0.45512602, 0.4606386 , 0.8167643 ,\n",
        "       0.8941993 , 0.9816452 , 0.8484862 , 0.4845052 , 0.41742828,\n",
        "       0.84974796, 0.82357126, 0.49063852, 0.49219918, 0.39795652,\n",
        "       0.67363465, 0.73317367, 0.93525606, 0.5202394 , 0.32772982,\n",
        "       0.8310231 , 0.9044254 , 0.22956057, 0.75961393, 0.53262824,\n",
        "       0.8791613 , 0.80461895, 0.5887064 , 0.8596254 , 0.8922224 ,\n",
        "       0.5017238 , 0.9132722 , 0.19728266, 0.5235329 , 0.7374937 ,\n",
        "       0.7826492 , 0.5670172 , 0.9160418 , 0.20804617, 0.99145913,\n",
        "       0.28570217, 0.73312855, 0.9230574 , 0.9541542 , 0.10144516,\n",
        "       0.62097186, 0.6816477 , 0.78581095, 0.9837593 , 0.94905704,\n",
        "       0.71971637, 0.8321574 , 0.91323316, 0.9318496 , 0.5806957 ,\n",
        "       0.61519545, 0.7948135 , 0.4935342 , 0.07121984, 0.5206881 ,\n",
        "       0.8226213 , 0.7971769 , 0.87895525, 0.57502794, 0.9876452 ,\n",
        "       0.8668947 , 0.23928548, 0.4277811 , 0.75448805, 0.6563984 ,\n",
        "       0.9764673 , 0.8205087 , 0.8265917 , 0.70568913, 0.6735427 ,\n",
        "       0.5359075 , 0.13506152, 0.9475714 , 0.896894  , 0.54826105,\n",
        "       0.71319175, 0.98505396, 0.8534989 , 0.7048005 , 0.3078328 ,\n",
        "       0.4713511 , 0.8451581 , 0.6944817 , 0.61611015, 0.38219497,\n",
        "       0.50654477, 0.39816618, 0.5889814 , 0.57422405, 0.7931625 ,\n",
        "       0.53374004, 0.3844996 , 0.6521951 , 0.7676469 , 0.74009264,\n",
        "       0.8066693 , 0.8690667 , 0.9025249 , 0.7467051 , 0.44806758,\n",
        "       0.5645702 , 0.62940985, 0.97143555, 0.8966346 , 0.952039  ,\n",
        "       0.8182383 , 0.9093747 , 0.7521274 , 0.50623196, 0.7357618 ]"
      ],
      "metadata": {
        "id": "l2gHOFdQb0Xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m= [] # Для нахождения среднего и другой статистики среди верно и неверно распознанных\n",
        "b=[]\n",
        "for i,e in enumerate(l):\n",
        "  if e < 0.5:\n",
        "    m.append(len(pairs[i][0]))\n",
        "  else:\n",
        "    b.append(len(pairs[i][0]))\n",
        "\n",
        "print(sum(m)/len(m) - sum(b)/len(b))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bBSD76Zb55X",
        "outputId": "d6b9aedd-a199-48ec-82f7-94e5268c8b41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "386.8505905813772\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(titles)) #проверка пар (саммари, заголовок)\n",
        "model.predict(titles[:100])"
      ],
      "metadata": {
        "id": "P_HRr4VvmpDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "qkcWHUE7dB8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Импортируем необходимые библиотеки для суммаризации\n",
        "from typing import List, Tuple\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"csebuetnlp/mT5_multilingual_XLSum\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"csebuetnlp/mT5_multilingual_XLSum\")\n",
        "halumodel = CrossEncoder('vectara/hallucination_evaluation_model')"
      ],
      "metadata": {
        "id": "N3ucriRDfgbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция суммаризации текста.\n",
        "def summarize_text(text: str) -> str:\n",
        "    # Кодирование текста для подачи в модель\n",
        "    input_ids = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "\n",
        "    # Генерация суммаризации текста\n",
        "    summary_ids = model.generate(input_ids, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "\n",
        "    # Декодирование и возврат суммаризации\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "# Функция проверки на галлюцинации.\n",
        "def check_hallucination(text_pair: List[str]) -> float:\n",
        "    return halumodel.predict(text_pair)\n",
        "\n",
        "def process_texts(texts: List[str]) -> List[Tuple[str, str, bool]]:\n",
        "    results = []\n",
        "    for text in texts:\n",
        "        summary = summarize_text(text)\n",
        "        is_hallucination = check_hallucination([text, summary])\n",
        "        results.append((text, summary, is_hallucination))\n",
        "    return results\n",
        "\n",
        "# Пример использования\n",
        "texts = texts1[:50]  # Список русскоязычных текстов\n",
        "processed_texts = process_texts(texts)\n",
        "\n",
        "for original, summary, hallucination in processed_texts:\n",
        "    print(f\"Оригинал: {original}\\nСуммаризация: {summary}\\nГаллюцинация: {hallucination}\\n\")\n"
      ],
      "metadata": {
        "id": "JUlF349pgB1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#проверка конкретных значений\n",
        "k = 0\n",
        "summa = 0\n",
        "for original, summary, hallucination in processed_texts:\n",
        "    if hallucination > 0.9:\n",
        "      k+=1\n",
        "      print(summary,hallucination)\n",
        "    summa += hallucination\n",
        "print(k)\n",
        "print(summa/50)"
      ],
      "metadata": {
        "id": "nCnobiVSmfL2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}